# FLAN-T5-Small â†’ TFLite (INT8 dynamic), CPU-only
# Fixes "untracked resource" by exporting methods on a tf.Module that owns the model.
%pip -q install "tensorflow==2.19.0" "tf-keras==2.19.0" \
                "transformers==4.44.2" "huggingface_hub>=0.24.0" \
                "numpy==2.0.2" "protobuf==5.29.1" "ml-dtypes>=0.5.0"

import os, zipfile, gc
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"

import tensorflow as tf
try:
    tf.config.set_visible_devices([], "GPU")  # force CPU to avoid OOMs
except Exception:
    pass

from transformers import TFT5ForConditionalGeneration, T5Tokenizer
import numpy as np

MODEL_ID = "google/flan-t5-small"
OUT_DIR  = "flan_t5_small_tflite_min"
ENC_SAVED = os.path.join(OUT_DIR, "encoder_saved_model")
DEC_SAVED = os.path.join(OUT_DIR, "decoder_step_saved_model")
os.makedirs(OUT_DIR, exist_ok=True)

print("TF:", tf.__version__)

# Load tokenizer + TF model (from PyTorch weights)
tokenizer = T5Tokenizer.from_pretrained(MODEL_ID)
model = TFT5ForConditionalGeneration.from_pretrained(MODEL_ID, from_pt=True)
model.trainable = False

# Keep memory small
MAX_SRC_LEN = 64
D_MODEL = model.config.d_model

# ---------- Export modules that TRACK the model variables ----------
class EncoderExport(tf.Module):
    def __init__(self, model):
        super().__init__()
        self.model = model  # tracked

    @tf.function(
        input_signature=[
            tf.TensorSpec([None, MAX_SRC_LEN], tf.int32, name="input_ids"),
            tf.TensorSpec([None, MAX_SRC_LEN], tf.int32, name="attention_mask"),
        ]
    )
    def __call__(self, input_ids, attention_mask):
        enc = self.model.encoder(input_ids=input_ids,
                                 attention_mask=attention_mask,
                                 training=False)
        return {"encoder_last_hidden_state": enc.last_hidden_state}

class DecoderStepExport(tf.Module):
    def __init__(self, model):
        super().__init__()
        self.model = model  # tracked

    @tf.function(
        input_signature=[
            tf.TensorSpec([None, 1], tf.int32, name="decoder_input_ids"),
            tf.TensorSpec([None, MAX_SRC_LEN, D_MODEL], tf.float32, name="encoder_last_hidden_state"),
            tf.TensorSpec([None, MAX_SRC_LEN], tf.int32, name="encoder_attention_mask"),
        ]
    )
    def __call__(self, decoder_input_ids, encoder_last_hidden_state, encoder_attention_mask):
        # In TF T5 (transformers 4.44.x), call model.decoder(...) directly
        dec_out = self.model.decoder(
            input_ids=decoder_input_ids,
            encoder_hidden_states=encoder_last_hidden_state,
            encoder_attention_mask=encoder_attention_mask,
            use_cache=False,
            training=False,
        )
        logits = self.model.lm_head(dec_out.last_hidden_state)  # (B,1,V)
        return {"logits": logits}

enc_export = EncoderExport(model)
dec_export = DecoderStepExport(model)

# Warm-up trace (tiny tensors)
_dummy_inp_ids = tf.zeros([1, MAX_SRC_LEN], dtype=tf.int32)
_dummy_attn    = tf.ones([1, MAX_SRC_LEN], dtype=tf.int32)
enc_hidden = enc_export(_dummy_inp_ids, _dummy_attn)["encoder_last_hidden_state"]
_ = dec_export(tf.zeros([1,1], tf.int32), enc_hidden, _dummy_attn)

# ---------- Save SavedModels (the modules track the variables) ----------
tf.saved_model.save(enc_export, ENC_SAVED)
tf.saved_model.save(dec_export, DEC_SAVED)

# ---------- Convert to TFLite (INT8 dynamic only for low RAM/size) ----------
def convert_dynamic(saved_model_dir, out_path):
    conv = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
    conv.optimizations = [tf.lite.Optimize.DEFAULT]
    tfl = conv.convert()
    with open(out_path, "wb") as f:
        f.write(tfl)

ENC_TFL = os.path.join(OUT_DIR, "encoder_int8_dynamic.tflite")
DEC_TFL = os.path.join(OUT_DIR, "decoder_step_int8_dynamic.tflite")
convert_dynamic(ENC_SAVED, ENC_TFL); gc.collect()
convert_dynamic(DEC_SAVED, DEC_TFL); gc.collect()

# ---------- Zip + download ----------
zip_path = "flan_t5_small_tflite_min.zip"
with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as z:
    for root, _, files in os.walk(OUT_DIR):
        for f in files:
            z.write(os.path.join(root, f), arcname=os.path.relpath(os.path.join(root, f), "."))

print("Encoder:", os.path.getsize(ENC_TFL)//1024, "KB")
print("Decoder:", os.path.getsize(DEC_TFL)//1024, "KB")
print("Zip:", os.path.getsize(zip_path)//1024, "KB")

from google.colab import files
files.download(zip_path)

# Drive fallback (uncomment if mobile download prompt misbehaves)
# from google.colab import drive
# drive.mount('/content/drive', force_remount=True)
# !cp -v flan_t5_small_tflite_min.zip /content/drive/MyDrive/
